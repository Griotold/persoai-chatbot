import os
import pandas as pd
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from langchain.schema import Document
from pinecone import Pinecone

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

def load_and_check_data():
    """1. xlsx íŒŒì¼ ì½ê¸° ë° í™•ì¸"""
    print("\n[STEP 1] ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")
    
    file_path = 'data/qa_data.xlsx'
    df = pd.read_excel(file_path, header=None)
    
    print(f"âœ… íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {file_path}")
    print(f"ğŸ“Š ì „ì²´ í–‰ ìˆ˜: {len(df)}")
    
    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    print("\n=== ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 10í–‰) ===")
    print(df.head(10))
    print("\n=== ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ë§ˆì§€ë§‰ 10í–‰) ===")
    print(df.tail(10))
    
    return df

def parse_qa_data(df):
    """2. Q&A ë°ì´í„° íŒŒì‹±"""
    print("\n[STEP 2] ğŸ” Q&A íŒŒì‹± ì¤‘...")
    
    # ì‹¤ì œ ë°ì´í„°ëŠ” ì»¬ëŸ¼ 2ì— ìˆìŒ
    data_col = df[2].dropna().tolist()
    
    qa_list = []
    current_q = None
    
    for item in data_col:
        item_str = str(item)
        if item_str.startswith('Q.'):
            current_q = item_str
        elif item_str.startswith('A.') and current_q:
            qa_list.append({
                'question': current_q,
                'answer': item_str
            })
            current_q = None
    
    print(f"âœ… íŒŒì‹± ì™„ë£Œ: {len(qa_list)}ê°œì˜ Q&A ìŒ")
    
    # íŒŒì‹±ëœ ë°ì´í„° í™•ì¸
    print("\n=== íŒŒì‹±ëœ Q&A ë°ì´í„° í™•ì¸ ===")
    for i, qa in enumerate(qa_list[:3], 1):  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
        print(f"\n[{i}]")
        print(f"Q: {qa['question']}")
        print(f"A: {qa['answer'][:80]}...")  # ë‹µë³€ì€ 80ìê¹Œì§€ë§Œ
    
    if len(qa_list) > 3:
        print(f"\n... (ë‚˜ë¨¸ì§€ {len(qa_list) - 3}ê°œ ìƒëµ)")
    
    return qa_list

def create_documents(qa_list):
    """3. Document ê°ì²´ ìƒì„±"""
    print("\n[STEP 3] ğŸ“ Document ê°ì²´ ìƒì„± ì¤‘...")
    
    documents = []
    for idx, qa in enumerate(qa_list):
        # ì§ˆë¬¸ê³¼ ë‹µë³€ì„ í•¨ê»˜ page_contentì— ì €ì¥
        doc = Document(
            page_content=f"{qa['question']}\n{qa['answer']}",
            metadata={
                "question": qa["question"],
                "answer": qa["answer"],
                "id": idx
            }
        )
        documents.append(doc)
    
    print(f"âœ… Document ìƒì„± ì™„ë£Œ: {len(documents)}ê°œ")
    
    return documents

def embed_to_pinecone(documents):
    """4. Pineconeì— ì„ë² ë”© & ì—…ë¡œë“œ"""
    print("\n[STEP 4] ğŸš€ Pineconeì— ì„ë² ë”© ì¤‘...")
    
    # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
    embedding = OpenAIEmbeddings(model='text-embedding-3-large')
    
    # Pinecone ì„¤ì •
    index_name = 'persoai-index'
    
    # Pinecone ì¸ë±ìŠ¤ ì¡´ì¬ í™•ì¸
    pinecone_api_key = os.environ.get("PINECONE_API_KEY")
    pc = Pinecone(api_key=pinecone_api_key)
    
    existing_indexes = [index.name for index in pc.list_indexes()]
    if index_name not in existing_indexes:
        print(f"âŒ ì¸ë±ìŠ¤ '{index_name}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print("Pinecone ì½˜ì†”ì—ì„œ ì¸ë±ìŠ¤ë¥¼ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
        return None
    
    print(f"âœ… ì¸ë±ìŠ¤ í™•ì¸: {index_name}")
    
    # Pineconeì— ì„ë² ë”© & ì €ì¥
    print(f"â³ ì„ë² ë”© ì¤‘... (ì•½ 10-20ì´ˆ ì†Œìš”)")
    database = PineconeVectorStore.from_documents(
        documents=documents,
        embedding=embedding,
        index_name=index_name
    )
    
    print(f"âœ… ì„ë² ë”© ì™„ë£Œ! {len(documents)}ê°œì˜ ë¬¸ì„œê°€ Pineconeì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return database

def verify_embeddings():
    """5. ì„ë² ë”© ê²€ì¦"""
    print("\n[STEP 5] ğŸ” ì„ë² ë”© ê²€ì¦ ì¤‘...")
    
    # ì„ë² ë”© & ì¸ë±ìŠ¤ ë¡œë“œ
    embedding = OpenAIEmbeddings(model='text-embedding-3-large')
    index_name = 'persoai-index'
    
    database = PineconeVectorStore.from_existing_index(
        index_name=index_name,
        embedding=embedding
    )
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "Perso.aiëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "ì§€ì›í•˜ëŠ” ì–¸ì–´ëŠ”?",
        "ìš”ê¸ˆì œëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
    ]
    
    print("\n=== ê²€ì¦ í…ŒìŠ¤íŠ¸ ===")
    for query in test_queries:
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{query}'")
        results = database.similarity_search(query, k=2)
        
        if results:
            print(f"âœ… ê²€ìƒ‰ ê²°ê³¼ {len(results)}ê°œ ë°œê²¬")
            print(f"   ê°€ì¥ ìœ ì‚¬í•œ ì§ˆë¬¸: {results[0].metadata['question']}")
        else:
            print("âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
    
    print("\nâœ… ê²€ì¦ ì™„ë£Œ!")

def main():
    """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
    print("=" * 80)
    print("ğŸš€ Perso.ai Q&A ì„ë² ë”© ìŠ¤í¬ë¦½íŠ¸")
    print("=" * 80)
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ Error: OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")
        return
    
    if not os.getenv("PINECONE_API_KEY"):
        print("âŒ Error: PINECONE_API_KEYê°€ .env íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")
        return
    
    try:
        # 1. ë°ì´í„° ë¡œë“œ & í™•ì¸
        df = load_and_check_data()
        
        # 2. Q&A íŒŒì‹±
        qa_list = parse_qa_data(df)
        
        # 3. Document ìƒì„±
        documents = create_documents(qa_list)
        
        # 4. Pineconeì— ì„ë² ë”©
        database = embed_to_pinecone(documents)
        
        if database:
            # 5. ê²€ì¦
            verify_embeddings()
            
            print("\n" + "=" * 80)
            print("ğŸ‰ ì™„ë£Œ! ì´ì œ ì±—ë´‡ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ ì‹¤í–‰ ëª…ë ¹ì–´: streamlit run chat.py")
            print("=" * 80)
        
    except FileNotFoundError:
        print("\nâŒ Error: data/qa_data.xlsx íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        print(f"\nâŒ Error ë°œìƒ: {e}")
        raise

if __name__ == "__main__":
    main()